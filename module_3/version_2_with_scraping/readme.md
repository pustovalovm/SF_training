Это вторая версия, нацеленная, прежде всего, на сбор данных с TripAdvisor. Здесь нет детального и супер-подробного EDA, зато есть скрипт для утягивания с TA данных по более чем 3 миллинонам ресторанов. Скрипт написан на фреймворке scrapy, главное преимущество которого над другими методами - асинхронные запросы "из коробки", в результате чего за одну ночь можно все эти 3 миллиона страниц обойти.

Схема работы скрейпера такая - сначала запускаем скрипт get_links.py, который идёт на карту сайта TA, качает по ссылкам из неё xml-файлы со ссылками на страницу ресторана, парсит всё это дело и складывает ссылки в csv-файл. Можно отобрать топ-Х самых часто встречающихся городов. Скрипт get_links берёт на вход два параметра - расположение файла выгрузки (по умолчанию './review_links.csv') и ссылку на карту сайта
(по умолчанию https://www.tripadvisor.com/sitemap/2/en_US/sitemap_en_US_index.xml).

Дальше нужно перейти в папку TA_scraper, где расположен сам скрейпер, и запустить его командой


``scrapy crawl -a links_file=(ВОТ СЮДА ПОТАВИТЬ ПУТЬ К РЕЗУЛЬАТУ РАБОТЫ GET_LINKS.PY) -o ../dataset.csv -L ERROR TA_scraper``

Потом датасет положить в папку inputs и далее работать с IPYNB.

**Результат работы даже при небрежной подготовке данных MAE = 0.137, что гораздо лучше лучшего моего решения на данных соревнования (0.16+).**
