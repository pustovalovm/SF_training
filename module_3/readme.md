## Проект 3. "О вкусной и здоровой пище."
**Автор - Михаил Пустовалов**
Этот проект посвящен пронозированию рейтинга ресторана на сайте [www.tripadvisor.com](www.tripadvisor.com). \
В качестве датасета взяты данные для 40000 ресторанов в обучающей выборке, и 10000 на валидационной.
В папке inputs лежат обе выборки (обучающая выборка в файле main_task.csv, валидационная - kaggle_task.csv).

**В папке version_2_with_scraping лежит альтернативное исполнение проекта. Был написан скрейпер для TA, с помощью которого были извлечены данные для более чем 3 миллионов ресторанов, и после очень быстрой и небрежной их подготовки получена MAE 0.137**

[Блокнот на kaggle](https://www.kaggle.com/mikhailpustovalov/mikhail-pustovalov-sf-tripadvisor-rating-v1)\
[Соревнование на kaggle](https://www.kaggle.com/c/sf-dst-restaurant-rating)

**Структура** выборок идентична:
* Город 
* Кухня
* Ранг ресторана относительно других ресторанов в этом городе
* Цены в ресторане в 3 категориях
* Количество отзывов
* 2 последних отзыва и даты этих отзывов
* страница ресторана на tripadvisor [(пример страницы)](https://www.tripadvisor.ca/Restaurant_Review-g187791-d2397684-Reviews-Meze_Bistrot-Rome_Lazio.html)
* ID ресторана в TripAdvisor
* Рейтинг ресторана (для обучающей выборки)


При разведывательном анализе данных проведены следующие **действия:**

1. Первичная обработка данных: 
    * проверена корректность данных
    * определён уникальный идентификатор для каждой записи
    * найдены дубликаты
    * найдены пустые значения, исправлены
    * значения отформатированы в подходящий формат
    * положение ресторнов в рейтинге нормализовано по городам
2. Сгенерированы новые признаки на основании списков кухонь, подаваемых в ресторанах (есть редкие кухни, есть популярные кухни, общее число кухонь в ресторане). 
3. Обработаны данные о датах последних 2 отзывов: сгенерированы новые признаки, такие как даты первого и последнего отзыва, разница по времени между ними, отметки об отсутствии одной или обеих дат.
4. Обработаны данные об общем количестве отзывов - проверена корректность, заполнены пропуски.
5. Проведён анализ слов, используемых в отзывах на рестораны, выделены "хорошие" и "плохие слова". Сформированы "рейтинги" на основе слов.
6. Добавлены данные по населению городов из внешнего источника.
7. Сгенерированы dummy-переменные для качественных признаков (города и страны расположения, ценовой диапазон, отстутствие отзывов).
8. Проверена корреляция признаков друг с другом и с целевой переменной.

После EDA сформирована **функция для подготвки данных**.

Создана и обучена модель Random Forest, библиотека sklearn. МОдель проверена на валидационной выборке. Критерий оценки качества - MAE (средняя абсолютная ошибка).
Результат по MAE **0.202** (т.е. прогноз отличается от действительности в среднем на 0.2). Установлено, что округление прогнозов до 0.5 существенно улучшает результат до **0.17**, поскольку оригинальные рейтинги округляются до 0.5.


В результате работы сформулированы следующие **выводы:**

1. В очередной раз важность EDA и проверки данных.
2. Установлена важность анализа структуры и распределения целевой переменной на обучающей выборке и важность получения прогноза той же структуры, что и целевая переменная.
3. Определены признаки, наиболее важные для модели:
    * рейтинг ресторана в городе (нормированный и ненормированный)
    * количество отзывов
    * находится ли ресторан в Риме :blush: :spaghetti: :pizza:
    * даты последних двух отзывов и промежуток между ними
    * население города
    * количество кухонь
    * находится ли ресторан в Мадриде :blush: (причем рестораны в Мадриде имеют в среднем невысокий рейтинг, т.е. влияет в отрицательном направлении)
    * количество популярных кухонь в ресторане
    * рейтинги по "хорошим" и "плохим" словам
4. Важность дополнительных данных - добавление данных по населению и странам несколько улучшило прогноз (порядок - сотые).
5. Главный вывод: для любой выборки существуе "потолок" точности. Если в потолок упёрлись, то имеет смысл не генерировать какие-то особо заковыристые признаки из имеющихся, а попробовать раздобыть новые данные. Возможно, имеет смысл какое-то время посвятить настройке самой модели, но по условиям проекта это делать нельзя.
6. **С TA были утянуты данные более чем 3 млн. ресторанов при помощи самодельного скрейпера**. При помощи этих данных была получена точность в 0.137 против 0.17, и это с учётом очень небрежной их подготовки для модели.

В репозитории хранятся файлы:

1. readme.md - этот файл  
2. /inputs/main_task.csv - обучающая выборка
3. /inputs/kaggle_task.csv - валидационная выборка
4. /inputs/global-city-population-estimates.xls - где-то нагугленные данные по популяции городов. Да, было бы быстрее записать руками, но это неинтересно.
5. **sf-tripadvisor-rating-v1-for-github.ipynb** - главный файл проекта, блокнот Jupyter.
6. /outputs/requirements.txt - зависимости из pip freeze
7. /outputs/submission.csv - результат работы модели на валидационной выборке
