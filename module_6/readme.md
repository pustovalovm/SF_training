## Проект 6. "Выбираем авто выгодно."
**Автор - Михаил Пустовалов**\
Этот проект посвящен предсказанию цены автомобиля на сайте auto.ru. Особенностью проекта является то, что отсутствует обучающая выборка, и данные надо собирать самостоятельно. Для этих целей был написан парсер сайта на фремворке scrapy. Парсер и ноутбук для его запуска находятся в папке scraping. При помощи парсера была собрана выборка из 300000+ объявлений, актуальных на 17.03.2021.
[Выборка загружена на kaggle, в репозитории её нет.](https://www.kaggle.com/mikhailpustovalov/autoru-all-used-car-offers-as-of-17032021)
Для обработки и загрузки дополнительных данных тестовой выбоки её необходимо положить в папку input.

Целевой метрикой в соревновании является MAPE. Следует учитывать, что обучающая и тестовая выборки были собраны с разрывом в несколько месяцев, за которые цены на автомобили выросли на несколько процентов.

[Соревнование на kaggle](https://www.kaggle.com/c/sf-dst-car-price-prediction)

Подробный EDA находится в ноутбуке **[SF-DST] Car Price Prediction EDA.ipynb**

При разведывательном анализе данных проведены следующие **действия:**

1. EDA с заполнением пропусокв, анализом распределений, принятием решений о той или иной обработке фичей.
2. Приведение выборок в единый формат.
3. Написание класса для обработки выборок, находится в файле **data_processing.py**.
   
После EDA проведена серия экспериментов с различными моделями машинного обучения, находится в ноутбуке **[SF-DST] Car Price Prediction ML.ipynb**. Рассмотрены нижеперечисленные модели и ансамбли, а также подобраны некоторые гиперпараметры этих моделей:

* OLS-регрессия (красиво взрывается)
* RIDGE-регрессия
* Бэггинг над RIDGE-регрессией
* K ближайших соседей
* Random Forest
* XGBoost
* CatBoost
* Наивное усредненение результатов алгоритмов
* Стэкинг всех алгоритмов
* Стэкинг топ-3 алгоритмов по метрике на валидационной выборке.

Удалось достичь значения метрики 12.70860 по тестовой выборке.

 **Выводы:**

1. Отмечен эффект разницы во времени сбора тестовой и обучающей выборки. Целевая переменная (цена) в тестовой выборке отстаёт по времени от обучающей, поэтому метрика на валидации получается лучше, чем на тесте. В данном случае это исправляется простой поправкой на инфляцию, но не всегда может быть всё так просто.
2. Проверены одиночные алгоритмы машинного обучения. По результатам можно сказать, что не всегда сложные алгоритмы типа XGBoost дают результат лучше, чем простая ридж-регрессия. Но это, возможно, связано с тем, что эти алгоритмы требуют более сложной настройки и осознанного подбора многих гиперпараметров.
3. Использование нескольких алгоритмов в ансамбле даёт определённый прирост метрики, как в случае простого усреднения, так и в случае стэкинга.

**Структура репозитория:**

1. readme.md - этот файл  
2. environment.yml - файл для создание виртуального окружения Anaconda для запуска проекта
3. /scraping - папка со скрейпером и ноутбуком для его запуска (scraping.ipynb)
4. /input/sample_submission.csv - пример сабмита на кэггл, по сути просто плейсхолдер для структуры папок
5. /outut/stacking_champions.csv - наилучший сабмит, а также плейсхолдер для структуры папок 
6. [SF-DST] Car Price Prediction EDA.ipynb - ноутбук с EDA
7. [SF-DST] Car Price Prediction ML.ipynb - ноутбук с ML